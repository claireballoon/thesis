\section{User Requirements}

The objective of this program is to classify tweets using the \#MeToo hashtag, and the core goal is to output a categorization that is as accurate as possible. The classification index of harassment and the ground truth dataset built will help the program ascertain three levels of classification to each tweet. This thesis also contains an evaluate of the classifier model. The last requirement is to build an online UI such that anyone can upload their dataset and, if formatted properly, receive the categorization results of the classifier.

\section{Development, Design, and Deployment}

This project is written with the Python programming language, chosen for its flexibility from the high quantity of libraries available to assist in natural language processing and for supervised machine learning. The pandas library was used to handle the datasets through DataFrame objects, NLTK was used for its text pre-processing features, and spaCy for more powerful prep-processing features. The scikit-learn library was used for classification algorithms and . Jupityr will be used to handle the preprocessing and exporting of the dataset. Matplotlib has been used be used for basic visualizations using the completed dataset.


Dr. Hassan has already collected the dataset, which amasses to approximately half a million tweets of data. Currently, I have manually labeled 1,000 of the tweets according to the proper categorization with the intention to raise that number up to 10,000 manually labeled tweets for the purposes of supervised machine learning. To verify the integrity of my categorization definitions, multiple volunteers of both genders are categorizing the dataset alongside me. The project is hosted on my personal GitHub account under the username “claireballoon”.

While the program can categorize a local dataset simply by running it in Python3 and outputting a file with proper categorization, further utility is desired from this project. The immediate step after completion of the categorization is to create a simple online interface for researchers to use to categorize their data without having to install Python and categorize them locally. Accomplish our core goals necessitates only the installation of Python3 and the appropriate libraries for those wishing to categorize their own datasets of tweets. As Jupityr can export to PDF or LaTeX, no further environment specifications are needed for researchers looking to use the results of this categorization in their data at this time.

\section{Architecture}

Supervised machine learning first requires the raw data to be properly formatted as needed as well as manually classified in order to form a reliable training set. The original, classified set of data is broken up into two sets of roughly 20\% (test set) and 80\% (train set) of the original. The train set is used alongside the classification rules and machine-learning algorithm being used to develop the model. The test set is used twice: once with the classification removed to which the model is applied, and once at the end with the classification kept in order to compare the accuracy.
\hfill \break

\begin{figure}[H]
\input{fig1-architecture}
\caption{Supervised Machine Learning Architecture}
\end{figure}


\section{User Interfaces}

There are two ways to apply the model. The user can use the command line and a csv file with the dataset of tweets formatted properly (ID of the tweet and the text contained within the tweet). The program will then output a new file with the categorizations and possibly some visualizations. However, this requires the installation of Python3 as well as libraries, packages, and dependencies and can be an inefficient process. Therefore, an online UI has been built that allows the user to see the display of findings and to explore the tool as a testing feature.

\section{Testing and Integration}

The initial hand-tagged tweets will be used to verify whether or not the program has successfully categorized the tweets. By manually categorizing a large enough data set, it can be determined with a high degree of accuracy how successful the algorithm and project will be. Figure 4.2 shows the algorithmic flow in optimizing and testing the accuracy of a model.

\begin{figure}[H]
    \input{fig2-testintegration}
    \caption{Testing and Integration Flow}
\end{figure}

The models are repeatedly tweaked and optimized until a satisfactory level of accuracy has been achieved. The pre-processing phase initially includes nothing, but after the overall pipeline has been established is continuously revisited and hyper-tuned. This includes the removal of stop words (ex. ....), removal of URLs, removal of username mentions beginning with the @ symbol, the removal of other punctuation, and more. The pre-procesing phase also tokenizes the tweets into ``tokens" that create the vocabulary. From there, the vocabulary is vectorized and each token is weighted with its value in the dictionary.

In the training phase, the dataset is split into a train and test set. A machine learning algorithm (SVM, Naive-Bayes, etc.) is applied to the training set with the new vocabulary established during the pre-processing phase, and the test set is used to evaluate the accuracy of that model. If the desired accuracy is not achieved, there are optimization options available, such as hyper parameter tuning. 
